<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>ChatGPT 提示工程师学习笔记 - 比特垃圾桶</title><meta name=Description content="基于 hugo 搭建的个人博客，这里我们将深入探讨后端技术、云计算、人工智能等领域的实战经验与技巧分享，同时涵盖个人成长、生活感悟、职场经验等独到见解。"><meta property="og:title" content="ChatGPT 提示工程师学习笔记"><meta property="og:description" content="LLM 类型 LLM 是 large language models 的缩写，目前大致分为两种类型：基础大型模型（Base LLM）和指令调整模型（Instruction Tuned LLM）。 基础大型模型通"><meta property="og:type" content="article"><meta property="og:url" content="https://aladdinding.cn/chatgpt%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><meta property="og:image" content="https://aladdinding.cn"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-08T09:30:57+08:00"><meta property="article:modified_time" content="2023-05-08T09:30:57+08:00"><meta property="og:site_name" content="Bitbucket"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://aladdinding.cn"><meta name=twitter:title content="ChatGPT 提示工程师学习笔记"><meta name=twitter:description content="LLM 类型 LLM 是 large language models 的缩写，目前大致分为两种类型：基础大型模型（Base LLM）和指令调整模型（Instruction Tuned LLM）。 基础大型模型通"><meta name=application-name content="比特垃圾桶"><meta name=apple-mobile-web-app-title content="比特垃圾桶"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://aladdinding.cn/chatgpt%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/><link rel=prev href=https://aladdinding.cn/go-mod%E6%8B%89%E5%8F%96%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"ChatGPT 提示工程师学习笔记","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/aladdinding.cn\/chatgpt%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\/"},"genre":"posts","keywords":"gpt","wordcount":2823,"url":"https:\/\/aladdinding.cn\/chatgpt%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\/","datePublished":"2023-05-08T09:30:57+08:00","dateModified":"2023-05-08T09:30:57+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"大猫"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=比特垃圾桶><span id=id-1 class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>时间轴 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/about/>关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=比特垃圾桶><span id=id-2 class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title>时间轴</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/about/ title>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">ChatGPT 提示工程师学习笔记</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>大猫</a>
</span>&nbsp;<span class=post-category>included in <a href=/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/><i class="far fa-folder fa-fw" aria-hidden=true></i>学习记录</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2023-05-08>2023-05-08</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;2823 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;6 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#llm-类型>LLM 类型</a></li><li><a href=#提示工程指南>提示工程指南</a><ul><li><a href=#编写清晰明确的提示>编写清晰明确的提示</a></li><li><a href=#给-llm-思考的时间>给 LLM 思考的时间</a></li></ul></li><li><a href=#llm-的局限>LLM 的局限</a></li><li><a href=#迭代提示开发>迭代提示开发</a></li><li><a href=#llm-可完成的任务>LLM 可完成的任务</a><ul><li><a href=#摘要>摘要</a></li><li><a href=#推断>推断</a></li><li><a href=#文本转换>文本转换</a></li><li><a href=#扩展>扩展</a></li></ul></li><li><a href=#总结>总结</a></li><li><a href=#附录>附录</a></li></ul></li></ul></nav></div></div><div class=content id=content><h2 id=llm-类型>LLM 类型</h2><p>LLM 是 large language models 的缩写，目前大致分为两种类型：基础大型模型（Base LLM）和指令调整模型（Instruction Tuned LLM）。</p><p>基础大型模型通过对文本训练集的预测下一个词来进行预训练生成。例如，如果输入是 “What is the capital of France?”，输出可能是 “What is France&rsquo;s largest city? What is France&rsquo;s population? What is the currency of France?”，因为训练集可能包含关于法国的问题列表。</p><p>指令调整模型经过微调和人类反馈强化学习（RLHF）后，对输入 “What is the capital of France?” 这类问题更倾向于输出“Paris”。因此，建议基于指令调整模型构建应用，因为它更具智能性且无害。</p><p>GPT-4 已采用部分指令调整模型优化技术，因此在理解和响应用户指令方面表现优越，介于普通 LLM 和指令调整模型之间。</p><h2 id=提示工程指南>提示工程指南</h2><h3 id=编写清晰明确的提示>编写清晰明确的提示</h3><p>策略一：使用分隔符，分隔符可以是任何将特定文本部分与 prompt 的其余部分分开的符号，例如 &lsquo;```, &lt;>, XML 符号等；使用分隔符还可以避免 prompt injection（提示词注入）。</p><blockquote><p>将用三个反引号分隔的文本总结为一句话。&rsquo;&rsquo;&rsquo;{text}&rsquo;&rsquo;&rsquo;。</p></blockquote><p>策略二：结构化输出。要求模型输出结构化格式，如 HTML 或 JSON 格式。</p><blockquote><p>生成一个包含三本虚构书籍的列表，附上作者和类型。以 JSON 格式提供，使用以下键：book_id, title, author, genre。</p></blockquote><p>策略三：检查条件是否满足。检查完成任务所需的假设是否满足，如果不满足，则中止任务。</p><blockquote><p>您将获得一段文本。如果其中包含一系列说明，请按照以下格式重写这些说明：</p></blockquote><blockquote><p>第 1 步 - … 第 2 步 -… 第 N 步 -…</p></blockquote><blockquote><p>如果文本中没有包含说明序列，请简单写下 “未提供步骤。”</p></blockquote><p>策略四：少样本提示。在执行任务之前，向模型提供一些成功执行任务的示例。</p><blockquote><p>您的任务是以一致的风格回答。 <child>: 教我了解耐心。 <grandparent>: 深刻的峡谷是由谦逊的泉水雕刻而成；宏伟的交响乐起源于单一的音符；最复杂的挂毯始于孤独的线程。 <child>: 教我了解恢复力。</p></blockquote><h3 id=给-llm-思考的时间>给 LLM 思考的时间</h3><p>重建推理链或序列。如果任务过于复杂，模型可能会编造答案（就像人一样）。</p><p>策略一：阐明完成任务所需的步骤。</p><blockquote><p>执行以下操作：1 - 将用三个反引号分隔的文本总结为一句话。2 - 将摘要翻译成法语。3 - 列出法语摘要中的每个名称。4 - 输出一个包含以下键的 json 对象：french_summary，num_names。用换行符分隔您的答案。文本：&rsquo;&rsquo;&rsquo;{text}&rsquo;&rsquo;'</p></blockquote><p>策略二：在模型急于得出结论之前，引导它推理出自己的解决方案。</p><blockquote><p>您的任务是判断学生的解决方案是否正确。要解决这个问题，请执行以下操作：- 首先，自己解决这个问题。- 然后将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在您自己解决问题之前，不要判断学生的解决方案是否正确。</p></blockquote><h2 id=llm-的局限>LLM 的局限</h2><p>幻觉（Hallucination）：给出一些看起来有道理，但实际上是错误的断言。PS：就是我们经常说的一本正经胡说八道！</p><blockquote><p>告诉我有关 Boie 公司的 AeroGlide UltraSlim 智能牙刷的信息。</p></blockquote><p>降低幻觉的方法：首先要求模型从给定的资料中寻找相关信息，然后基于相关信息回答问题。</p><h2 id=迭代提示开发>迭代提示开发</h2><p>很少有人一开始编写 Prompt 就能取得成功，关键在于在这个过程中不断迭代你的 Prompt。迭代步骤如下：</p><ol><li>编写清晰、具体的 Prompt，给系统充足的思考时间</li><li>运行并查看结果</li><li>分析为什么未达到预期的效果</li><li>调整想法和 Prompt，然后重复以上步骤。</li></ol><p>没有一个通用的、完美的 Prompt！成为提示工程师的关键不在于知道最完美的 Prompt，而在于拥有一个良好的开发迭代 Prompt 的流程。</p><h2 id=llm-可完成的任务>LLM 可完成的任务</h2><h3 id=摘要>摘要</h3><ul><li>结合 prompt 原则，写出清晰的任务描述</li><li>针对特定的业务（或关注点），聚焦于不同的内容</li><li>⼀些特殊业务（或关注点），使⽤提取⽐总结更好</li></ul><p>案例：对电商产品评价进⾏总结或提取</p><blockquote><p>请在 30 字内总结以下评论，并关注与价格和感知价值相关的方面，以便向负责确定产品价格的定价部门提供反馈。</p></blockquote><blockquote><p>请为电商网站上的产品评论生成一个简短的总结，以便向定价部门提供反馈，该部门负责确定产品的价格。请在不超过 30 个单词的情况下总结以下评论，并关注与价格和感知价值相关的任何方面。</p></blockquote><h3 id=推断>推断</h3><ul><li>如果⾃⼰训练和部署识别情感的模型是⼀个很⼤的⼯作量，但是对
于⼤模型来说就是⼀个 prompt 的事</li><li>LLM ⽂本推理能⼒简化了机器学习⼈员的时间（传统⽅式可能需要
⼏周时间）</li><li>LLM 在提取⽅⾯⾮常出⾊，可以指定关注点 / 关键字或指定输出格式，⽐如 JSON</li></ul><p>案例：电商⽹站评价列表中识别⽂本情感，prompt 关键字： sentiment</p><blockquote><p>从评论文本中识别以下项目：</p><ul><li>情感（正面或负面）</li><li>评论者是否表达了愤怒？（真或假）</li><li>评论者购买的物品</li><li>制造该物品的公司</li></ul><p>评论以三个反引号为界限。请将您的回答格式化为一个 JSON 对象，其中包含 “Sentiment”、“Anger”、“Item” 和“Brand”作为键。如果信息不存在，请使用 “unknown” 作为值。尽可能缩短您的回答。将 Anger 值格式化为布尔值。</p><p>注：可以同时做多项任务推断（情感、是否⽣⽓、产品和品牌名称）</p></blockquote><p>案例：根据⼀段新闻推断主题，⽐如 NASA 的新闻稿，利⽤提取能⼒：识别 topic/tag ，并且可以分类</p><blockquote><p>请判断以下每个主题是否在下面的文本中，文本以三个反引号为界限。请将您的答案表示为一个列表，每个主题为 0 或 1。
主题列表：{",".join(topic_list)}
文本示例：&rsquo;&rsquo;&rsquo;{story}&rsquo;''</p><p>注：这⾥ prompt ⾥使⽤了 python 代码。llm 应该可以识别。</p></blockquote><h3 id=文本转换>文本转换</h3><ul><li><p>翻译：⾃然语⾔语种转换</p><blockquote><p>将下面的英文翻译成西班牙语：</p><p>```Hi, I would like to order a blende```</p></blockquote><blockquote><p>告诉我这是哪种语言：</p><p>```Combien coûte le lampadaire?```</p></blockquote></li><li><p>语⽓转换</p><blockquote><p>将下面这段话以正式、非正式的语气翻译出来：</p><p>```Would you like to order a pillow?```</p></blockquote><blockquote><p>以商务语气来输出邮件：</p><p>```Dude, This is Joe, check out this spec on this standing lamp.```</p></blockquote></li><li><p>格式转换</p><blockquote><p>将下面的 python 字典从 JSON 转换至 HTML：</p><p>{data_json}</p></blockquote></li><li><p>校对并改正语法错误</p><blockquote><p>请提供您希望校对和修改的文本。如果您没有发现任何错误，请回答 “未发现错误”。请勿在文本周围使用任何标点符号。</p><p>```{text}```</p></blockquote><blockquote><p>请提供您希望校对、修改并使其更具吸引力的评论。确保其遵循 APA 风格指南并针对高级读者。请以 markdown 格式输出。</p><p>```{text}```</p></blockquote></li></ul><h3 id=扩展>扩展</h3><ul><li>将短⽂本扩展为更⻓的任务</li></ul><p>案例：根据客户评论和识别评论情感，生成回复客户的定制邮件。</p><blockquote><p>您是一名客户服务的 AI 助手。您的任务是发送一封回复邮件给一位重要的客户。请提供被限定为三个单引号的客户电子邮件，生成一封回复邮件以感谢客户的评论。如果情感是积极或中性的，感谢他们的评论。如果情感是消极的，道歉并建议他们联系客户服务。确保使用评论中的具体细节。用简洁而专业的语气写信，并在结尾签上 “AI 客户代理” 字样。</p></blockquote><h2 id=总结>总结</h2><ul><li>给出清晰、具体的指令是与模型交互的重要原则之一，同时需要给予模型思考的时间，以便它能够更好地理解和回答问题。</li><li>迭代提示词可以帮助我们进一步优化模型，使其更准确地理解和回答问题。</li><li>大型语言模型具有许多强大的能力，如生成摘要、推理、转换和拓展等，这些能力可以被用来构建聊天机器人等各种应用。</li></ul><h2 id=附录>附录</h2><p>视频中小姐姐的英文有一股伦敦腔，听起来还是很舒服的</p><p>原视频地址：</p><p><a href=https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction target=_blank rel="noopener noreffer">https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction</a></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2023-05-08</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/gpt/>gpt</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/go-mod%E6%8B%89%E5%8F%96%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/ class=prev rel=prev title="Go Mod 拉取私有仓库"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Go Mod 拉取私有仓库</a></div></div><div id=comments><div id=utterances class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>Utterances</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2019 - 2023</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>大猫</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span><span class=icp-splitter>&nbsp;|&nbsp;</span><br class=icp-br><span class=icp><a href=https://beian.miit.gov.cn/ rel="noopener noreferrer" target=_blank>鄂ICP备2021016339号-1</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/algoliasearch/algoliasearch-lite.umd.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/plugins/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/plugins/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/typeit/index.umd.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:100},comment:{utterances:{darkTheme:"github-dark",issueTerm:"og:title",label:"",lightTheme:"github-light",repo:"munding/aladdinding.github.io"}},data:{"id-1":"/dev/null","id-2":"/dev/null"},lightgallery:!0,search:{algoliaAppID:"8X683FLT7W",algoliaIndex:"aladdinding",algoliaSearchKey:"2f355171a5a5015687f75fa67becee4c",highlightTag:"em",maxResultLength:10,noResultsFound:"No results found",snippetLength:50,type:"algolia"},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"id-1":["id-1"],"id-2":["id-2"]},duration:-1,speed:100}}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-G3C60BHX8Z",{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-G3C60BHX8Z" async></script></body></html>